
     * Massachusetts Institute of Technology

     * News
     * Video
     * Social

   Follow MIT
     * MIT News RSS
     * Follow MIT on Twitter
     * Follow MIT on Facebook
     * Follow MIT on Google+
     * Follow MIT on Instagram
     * Follow MIT on Flickr
     * Follow MIT on YouTube

   MIT News Office

MIT News Office

   Browse or
   ____________________ Submit

Browse

     *

Most Popular
          + Study: Online classes really do work
          + Chemists recruit anthrax to deliver cancer drugs
          + Using science for service
          + Q&A: Science journalism and public engagement
          + Can you out-race a computer?
          + Letter to the community on East Campus/Kendall Square design
            firm selection
          + Community picnic to honor former ombudsperson Mary Rowe
          + 3 Questions: Calestous Juma on African development
     *

By Topic
          + Computer Science and Artificial Intelligence Laboratory
            (CSAIL)
               o Can you out-race a computer?
               o MIT Professional Education announces new offerings of
                 Online X professional course on big data
               o Fingertip sensor gives robot unprecedented dexterity
               o Will tomorrow’s robots move like snakes?
          + Computer vision
               o Can you out-race a computer?
               o Fingertip sensor gives robot unprecedented dexterity
               o Where to grab space debris
               o An end to drug errors?
          + Electrical Engineering & Computer Science (eecs)
               o Can you out-race a computer?
               o Battling superbugs
               o Engineered proteins stick like glue — even in water
               o Magnetic fields make the excitons go ’round
          + Imaging
               o Extracting audio from visual information
               o [20130729121753-0.jpg?itok=y06kSlOK] McGovern Institute
                 gets new brain scanner
               o Multiview 3-D photography made simple
               o [20130104145954-3.jpg?itok=yGDImtpd] Tiny tools help
                 advance medical discoveries
          + Research
               o How to make a “perfect” solar absorber
               o Know thy banker — it could keep you solvent
               o Biologists find an early sign of cancer
               o Underwater robot for port security
       See All Topics
     *

By School
          + School of Architecture + Planning
               o Soft design for a sustainable world
               o 3 Questions: Calestous Juma on African development
               o MacArthur confers “genius” awards for playful math and
                 practical art
               o Sheila Kennedy awarded $100K Berkeley-Rupp Prize
          + School of Engineering
               o How to make a “perfect” solar absorber
               o Underwater robot for port security
               o How to make stronger, “greener” cement
               o Can you out-race a computer?
          + School of Humanities, Arts, and Social Sciences
               o MIT presents new music series: MIT Sounding
               o Evan Lieberman: Southern Africa as a lens on ethnicity,
                 governance, and citizenship
               o Using science for service
               o The Scottish referendum: What it means
          + Sloan School of Management
               o Know thy banker — it could keep you solvent
               o New master's track established integrating design and
                 management
               o Paradigm shifter
               o MIT ranked as nation’s No. 7 university by U.S. News
          + School of Science
               o Biologists find an early sign of cancer
               o Voices of MIT at the People’s Climate March
               o Tania Baker to be honored with Arthur Kornberg and Paul
                 Berg Lifetime Achievement Award
               o Researchers engineer new mouse model to study disease
     *

By Department
          + History
               o Said and Done for Summer 2014
               o [20131229084159-1_1.jpg?itok=cLnFjT-9] Anthropologist
                 Manduhai Buyandelger wins the 2013 Levitan Prize in the
                 Humanities
               o [20131213180343-0.jpg?itok=ILMgDLvS] The surprising story
                 of Mongolian shamanism
               o [20131105143220-0_1.jpg?itok=1W6eEVA1] Dower granted
                 major ‘lifetime achievement’ award in history
          + Physical Education
               o Sports Shorts for March 17: A weekly wrap-up of MIT
                 varsity athletics
               o Sports Shorts for March 10: A weekly wrap-up of MIT
                 varsity athletics
          + and Recreation
               o Sports Shorts for March 17: A weekly wrap-up of MIT
                 varsity athletics
          + Civil and Environmental Engineering
               o How to make stronger, “greener” cement
               o How to hide like an octopus
               o Protecting infrastructure with smarter CPS
               o Summer scholars deepen research skills
          + Linguistics and Philosophy
               o Said and Done for Summer 2014
               o A new leadership model for a new Haiti
               o From contemporary syntax to human language’s deep origins
               o Philosopher Sally Haslanger receives Ford Chair
       See All Departments
     *

By Center, Lab, & Program
          + Computer Science and Artificial Intelligence Laboratory
            (CSAIL)
               o Can you out-race a computer?
               o MIT Professional Education announces new offerings of
                 Online X professional course on big data
               o Fingertip sensor gives robot unprecedented dexterity
               o Will tomorrow’s robots move like snakes?
          + Biomimetics Robotics Lab
               o Bound for robotic glory
          + Research Laboratory of Electronics
               o Study: Online classes really do work
               o Engineered proteins stick like glue — even in water
               o Magnetic fields make the excitons go ’round
               o Toward optical chips
          + Computer Science and Artificial Intelligence Laboratory
            (CSAIL)
               o Can you out-race a computer?
               o MIT Professional Education announces new offerings of
                 Online X professional course on big data
               o Fingertip sensor gives robot unprecedented dexterity
               o Will tomorrow’s robots move like snakes?
          + Technology and Policy Program
               o Shrink-wrapping spacesuits
               o True Diversity: A Multiplier in Global STEM Innovation
       See All Centers, Labs, & Programs

   Login or Subscribe Newsletter
     * Image: Christine Daniloff/MIT
       Full Screen

Extracting audio from visual information

   Algorithm recovers speech from the vibrations of a potato-chip bag
   filmed through soundproof glass. Watch Video

   Larry Hardesty | MIT News Office
   August 4, 2014
   Press Inquiries Share

Press Contact

   Abby Abazorius
   Email: abbya@mit.edu
   Phone: 617-253-2709
   MIT News Office

Media Resources

   1 images for download

   Access Media

   Media can only be downloaded from the desktop version of this website.

Share

Comment

   Leave a comment

   Researchers at MIT, Microsoft, and Adobe have developed an algorithm
   that can reconstruct an audio signal by analyzing minute vibrations of
   objects depicted in video. In one set of experiments, they were able to
   recover intelligible speech from the vibrations of a potato-chip bag
   photographed from 15 feet away through soundproof glass.

   In other experiments, they extracted useful audio signals from videos
   of aluminum foil, the surface of a glass of water, and even the leaves
   of a potted plant. The researchers will present their findings in a
   paper at this year’s Siggraph, the premier computer graphics
   conference.

   “When sound hits an object, it causes the object to vibrate,” says Abe
   Davis, a graduate student in electrical engineering and computer
   science at MIT and first author on the new paper. “The motion of this
   vibration creates a very subtle visual signal that’s usually invisible
   to the naked eye. People didn’t realize that this information was
   there.”

   Joining Davis on the Siggraph paper are Frédo Durand and Bill Freeman,
   both MIT professors of computer science and engineering; Neal Wadhwa, a
   graduate student in Freeman’s group; Michael Rubinstein of Microsoft
   Research, who did his PhD with Freeman; and Gautham Mysore of Adobe
   Research.

   Reconstructing audio from video requires that the frequency of the
   video samples — the number of frames of video captured per second — be
   higher than the frequency of the audio signal. In some of their
   experiments, the researchers used a high-speed camera that captured
   2,000 to 6,000 frames per second. That’s much faster than the 60 frames
   per second possible with some smartphones, but well below the frame
   rates of the best commercial high-speed cameras, which can top 100,000
   frames per second.

   Commodity hardware

   In other experiments, however, they used an ordinary digital camera.
   Because of a quirk in the design of most cameras’ sensors, the
   researchers were able to infer information about high-frequency
   vibrations even from video recorded at a standard 60 frames per second.
   While this audio reconstruction wasn’t as faithful as that with the
   high-speed camera, it may still be good enough to identify the gender
   of a speaker in a room; the number of speakers; and even, given
   accurate enough information about the acoustic properties of speakers’
   voices, their identities.

   The researchers’ technique has obvious applications in law enforcement
   and forensics, but Davis is more enthusiastic about the possibility of
   what he describes as a “new kind of imaging.”

   “We’re recovering sounds from objects,” he says. “That gives us a lot
   of information about the sound that’s going on around the object, but
   it also gives us a lot of information about the object itself, because
   different objects are going to respond to sound in different ways.” In
   ongoing work, the researchers have begun trying to determine material
   and structural properties of objects from their visible response to
   short bursts of sound.

   IFRAME: //www.youtube.com/embed/FKXOucXB4a8

   Watch how MIT researchers extract audio from the vibrations of a plant,
   potato-chip bag, and other objects.

   Video courtesy of the researchers

   In the experiments reported in the Siggraph paper, the researchers also
   measured the mechanical properties of the objects they were filming and
   determined that the motions they were measuring were about a tenth of
   micrometer. That corresponds to five thousandths of a pixel in a
   close-up image, but from the change of a single pixel’s color value
   over time, it’s possible to infer motions smaller than a pixel.

   Suppose, for instance, that an image has a clear boundary between two
   regions: Everything on one side of the boundary is blue; everything on
   the other is red. But at the boundary itself, the camera’s sensor
   receives both red and blue light, so it averages them out to produce
   purple. If, over successive frames of video, the blue region encroaches
   into the red region — even less than the width of a pixel — the purple
   will grow slightly bluer. That color shift contains information about
   the degree of encroachment.

   Putting it together

   Some boundaries in an image are fuzzier than a single pixel in width,
   however. So the researchers borrowed a technique from earlier work on
   algorithms that amplify minuscule variations in video, making visible
   previously undetectable motions: the breathing of an infant in the
   neonatal ward of a hospital, or the pulse in a subject’s wrist.

   That technique passes successive frames of video through a battery of
   image filters, which are used to measure fluctuations, such as the
   changing color values at boundaries, at several different orientations
   — say, horizontal, vertical, and diagonal — and several different
   scales.

   The researchers developed an algorithm that combines the output of the
   filters to infer the motions of an object as a whole when it’s struck
   by sound waves. Different edges of the object may be moving in
   different directions, so the algorithm first aligns all the
   measurements so that they won’t cancel each other out. And it gives
   greater weight to measurements made at very distinct edges — clear
   boundaries between different color values.

   The researchers also produced a variation on the algorithm for
   analyzing conventional video. The sensor of a digital camera consists
   of an array of photodetectors — millions of them, even in commodity
   devices. As it turns out, it’s less expensive to design the sensor
   hardware so that it reads off the measurements of one row of
   photodetectors at a time. Ordinarily, that’s not a problem, but with
   fast-moving objects, it can lead to odd visual artifacts. An object —
   say, the rotor of a helicopter — may actually move detectably between
   the reading of one row and the reading of the next.

   For Davis and his colleagues, this bug is a feature. Slight distortions
   of the edges of objects in conventional video, though invisible to the
   naked eye, contain information about the objects’ high-frequency
   vibration. And that information is enough to yield a murky but
   potentially useful audio signal.

   “This is new and refreshing. It’s the kind of stuff that no other group
   would do right now,” says Alexei Efros, an associate professor of
   electrical engineering and computer science at the University of
   California at Berkeley. “We’re scientists, and sometimes we watch these
   movies, like James Bond, and we think, ‘This is Hollywood theatrics.
   It’s not possible to do that. This is ridiculous.’ And suddenly, there
   you have it. This is totally out of some Hollywood thriller. You know
   that the killer has admitted his guilt because there’s surveillance
   footage of his potato chip bag vibrating.”

   Efros agrees that the characterization of material properties could be
   a fruitful application of the technology. But, he adds, “I’m sure there
   will be applications that nobody will expect. I think the hallmark of
   good science is when you do something just because it’s cool and then
   somebody turns around and uses it for something you never imagined.
   It’s really nice to have this type of creative stuff.”
     __________________________________________________________________

   Topics: Computer vision, Imaging, School of Engineering, Electrical
   Engineering & Computer Science (eecs), Computer Science and Artificial
   Intelligence Laboratory (CSAIL), Research

Comments

   View the discussion thread.

Press Mentions

     * Heather Kelly of CNN reports on how MIT researchers have developed
       a new technique to recreate audio from silent video. "We showed
       that we can determine pretty reliably the gender of a speaker from
       low-quality sound we managed to recover from a tissue box," says
       Dr. Michael Rubinstein.
       CNN
     * Colleen Shalby reports for the PBS NewHour on the “visual
       microphone” developed by MIT researchers that can detect and
       reconstruct audio by analyzing the sound waves traveling through
       objects.
       PBS NewsHour
     * Bloomberg Businessweek reporter Drake Bennett writes about how MIT
       researchers have developed a technique for extracting audio by
       analyzing the sound vibrations traveling through objects. Bennett
       reports that the researchers found that sound waves could be
       detected even when using cell phone camera sensors.
       Bloomberg Businessweek
     * Alyssa Newcomb of ABC News reports on how MIT researchers have
       developed a new method that can uncover intelligible audio by
       videotaping everyday objects and translating the sound vibrations
       back into intelligible sound.
       ABC News
     * NPR’s Melissa Block examines the new MIT algorithm that can
       translate visual information into sound. Abe Davis explains that by
       analyzing sound waves traveling through an object, “you can start
       to filter out some of that noise and you can actually recover the
       sound that produced that motion.”
       NPR
     * Rachel Feltman of The Washington Post examines the new MIT
       algorithm that can reconstruct sound by examining the visual
       vibrations of sound waves. “This is a new dimension to how you can
       image objects,” explains graduate student Abe Davis.
       The Washington Post
     * In a piece for Popular Science, Douglas Main writes on the new
       technique developed by MIT researchers that can reconstruct speech
       from visual information. The researchers showed that, “an
       impressive amount of information about the audio (although not its
       content) could also be recorded with a regular DSLR that films at
       60 frames per second.”
       Popular Science
     * Writing for Slate, Elliot Hannon reports on the new technology
       developed by MIT researchers that allows audio to be extracted from
       visual information by processing the vibrations of sound waves as
       they move through objects.
       Slate
     * Time reporter Nolan Feeney writes about how researchers from MIT
       have developed a new technique to extract intelligible audio of
       speech by “videotaping and analyzing the tiny vibrations of
       objects.”
       Time Magazine
     * Hal Hodson of New Scientist reports on the new algorithm developed
       by MIT researchers that can turn visual images into sound. "We were
       able to recover intelligible speech from maybe 15 feet away, from a
       bag of chips behind soundproof glass," explains Abe Davis, a
       graduate student at MIT.
       New Scientist
     * Michael Morisy writes for BetaBoston about an algorithm developed
       by MIT researchers that can recreate speech by analyzing material
       vibrations. “The sound re-creation technique typically required
       cameras shooting at thousands of frames per second,” writes Morisy.
       BetaBoston
     * “Researchers have developed an algorithm that can use visual
       signals from videos to reconstruct sound and have used it to
       recover intelligible speech from a video,” writes Katie Collins for
       Wired about an algorithm developed by a team of MIT researchers
       that can derive speech from material vibrations.
       Wired

Related

     * Paper: “The Visual Microphone: Passive Recovery of Sound from
       Video”
     * The Visual Microphone
     * Abe Davis
     * Computer Graphics Group
     * Computer Science and Artificial Intelligence Laboratory
     * School of Engineering

Archives

     * Seeing the human pulse
     * In these frames of video, a new algorithm amplifies the almost
       imperceptible change in skin color caused by the pumping of the
       blood. Researchers amplify variations in video, making the
       invisible visible
     * Faster computer graphics

About This Website

   This Website is maintained by the MIT News Office.
     * About the MIT News Office
     * MIT News Press Center
     * Press Inquries
     * Filming Guidelines
     * Contact Us
     * Terms of Use

     * RSS
     * Twitter
     * Facebook
     * Google+
     * Instagram
     * Flickr
     * YouTube

     * MIT Homepage
     * MIT Video
     * MIT Connect
     * MIT Resources
     * Events Calendar

     * About MIT
     * Admissions
     * Alumni
     * Education
     * Labs and Centers

Resources

     * Submit Campus News
     * Pitch a Story
     * Sign Up for Newsletter
     * Subscribe to Press Releases
     * Terms of Use

   GIVE TO MIT
   Massachusetts Institute of Technology

   MIT News Office • Building 11-400
   Massachusetts Institute of Technology • Cambridge, MA 02139-4307

   Back to the top
