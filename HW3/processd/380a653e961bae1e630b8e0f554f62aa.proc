   #publisher O'Reilly Radar » Feed O'Reilly Radar » Comments Feed
   O'Reilly Radar » AI’s dueling definitions Comments Feed Four short
   links: 17 June 2014 Four short links: 18 June 2014

   Menu

     * Home
     * Shop Books & Videos
     * Radar
     * Safari Books Online
     * Conferences
     * IT Courses & Certificates

   oreilly.com
   O'Reilly Radar
   RSS Feed Twitter Facebook Google+ Youtube

   Search______________
   SEARCH

     * Home
     * Shop Books & Videos
     * Radar
          + Radar
          + Animals
     * Safari Books Online
     * Conferences
     * IT Courses & Certificates

   Data
   More Topics
     * Data
     * Design
     * Emerging Tech
     * IoT+
     * Programming
     * Web Ops & Performance
     * Web Platform

     * Print
     * Listen

AI’s dueling definitions

Why my understanding of AI is different from yours.

   by Beau Cronin | @beaucronin | +Beau Cronin | Comments: 6 | June 17,
   2014
   Comments: 6
   SoftBank_Pepper

   SoftBank’s Pepper, a humanoid robot that takes its surroundings into
   consideration.

   Editor’s note: this post is part of our Intelligence Matters
   investigation.

   Let me start with a secret: I feel self-conscious when I use the terms
   “AI” and “artificial intelligence.” Sometimes, I’m downright
   embarrassed by them.

   Before I get into why, though, answer this question: what pops into
   your head when you hear the phrase artificial intelligence?

   For the layperson, AI might still conjure HAL’s unblinking red eye, and
   all the misfortune that ensued when he became so tragically confused.
   Others jump to the replicants of Blade Runner or more recent movie
   robots. Those who have been around the field for some time, though,
   might instead remember the “old days” of AI — whether with nostalgia or
   a shudder — when intelligence was thought to primarily involve logical
   reasoning, and truly intelligent machines seemed just a summer’s work
   away. And for those steeped in today’s big-data-obsessed tech industry,
   “AI” can seem like nothing more than a high-falutin’ synonym for the
   machine-learning and predictive-analytics algorithms that are already
   hard at work optimizing and personalizing the ads we see and the offers
   we get — it’s the term that gets trotted out when we want to put a high
   sheen on things.

   Like the Internet of Things, Web 2.0, and big data, AI is discussed and
   debated in many different contexts by people with all sorts of motives
   and backgrounds: academics, business types, journalists, and
   technologists. As with these other nebulous technologies, it’s no
   wonder the meaning of AI can be hard to pin down; everyone sees what
   they want to see. But AI also has serious historical baggage, layers of
   meaning and connotation that have accreted over generations of
   university and industrial research, media hype, fictional accounts, and
   funding cycles. It’s turned into a real problem: without a lot of
   context, it’s impossible to know what someone is talking about when
   they talk about AI.

   Let’s look at one example. In his 2004 book On Intelligence, Jeff
   Hawkins confidently and categorically states that AI failed decades
   ago. Meanwhile, the data scientist John Foreman can casually discuss
   the “AI models” being deployed every day by data scientists, and Marc
   Andreessen can claim that enterprise software products have already
   achieved AI. It’s such an overloaded term that all of these viewpoints
   are valid; they’re just starting from different definitions.

   Which gets back to the embarrassment factor: I know what I mean when I
   talk about AI, at least I think I do, but I’m also painfully aware of
   all these other interpretations and associations the term evokes. And
   I’ve learned over the years that the picture in my head is almost
   always radically different from that of the person I’m talking to. That
   is, what drives all this confusion is the fact that different people
   rely on different primal archetypes of AI.

   Let’s explore these archetypes, in the hope that making them explicit
   might provide the foundation for a more productive set of conversations
   in the future.
     * AI as interlocutor. This is the concept behind both HAL and Siri: a
       computer we can talk to in plain language, and that answers back in
       our own lingo. Along with Apple’s personal assistant, systems like
       Cortana and Watson represent steps toward this ideal: they aim to
       meet us on our own ground, providing answers as good as — or better
       than — those we could get from human experts. Many of the most
       prominent AI research and product efforts today fall under this
       model, probably because it’s such a good fit for the search- and
       recommendation-centric business models of today’s Internet giants.
       This is also the version of AI enshrined in Alan Turing’s famous
       test for machine intelligence, though it’s worth noting that direct
       assaults on that test have succeeded only by gaming the metric.
     * AI as android. Another prominent notion of AI views disembodied
       voices, however sophisticated their conversational repertoire, as
       inadequate: witness the androids from movies like Blade Runner, I
       Robot, Alien, The Terminator, and many others. We routinely
       transfer our expectations from these fictional examples to
       real-world efforts like Boston Dynamics’ (now Google’s) Atlas, or
       SoftBank’s newly announced Pepper. For many practitioners and
       enthusiasts, AI simply must be mechanically embodied to fulfill the
       true ambitions of the field. While there is a body of theory to
       motivate this insistence, the attachment to mechanical form seems
       more visceral, based on a collective gut feeling that intelligences
       must move and act in the world to be worthy of our attention. It’s
       worth noting that, just as recent Turing test results have
       highlighted the degree to which people are willing to ascribe
       intelligence to conversation partners, we also place unrealistic
       expectations on machines with human form.
     * AI as reasoner and problem-solver. While humanoid robots and
       disembodied voices have long captured the public’s imagination,
       whether empathic or psychopathic, early AI pioneers were drawn to
       more refined and high-minded tasks — playing chess, solving logical
       proofs, and planning complex tasks. In a much-remarked collective
       error, they mistook the tasks that were hardest for smart humans to
       perform (those that seemed by introspection to require the most
       intellectual effort) for those that would be hardest for machines
       to replicate. As it turned out, computers excel at these kinds of
       highly abstract, well-defined jobs. But they struggle at the things
       we take for granted — things that children and many animals perform
       expertly, such as smoothly navigating the physical world. The
       systems and methods developed for games like chess are completely
       useless for real-world tasks in more varied environments.Taken to
       its logical conclusion, though, this is the scariest version of AI
       for those who warn about the dangers of artificial
       superintelligence. This stems from a definition of intelligence
       that is “an agent’s ability to achieve goals in a wide range of
       environments.” What if an AI was as good at general problem-solving
       as Deep Blue is at chess? Wouldn’t that AI be likely to turn those
       abilities to its own improvement?
     * AI as big-data learner. This is the ascendant archetype, with
       massive amounts of data being inhaled and crunched by Internet
       companies (and governments). Just as an earlier age equated machine
       intelligence with the ability to hold a passable conversation or
       play chess, many current practitioners see AI in the prediction,
       optimization, and recommendation systems that place ads, suggest
       products, and generally do their best to cater to our every need
       and commercial intent. This version of AI has done much to propel
       the field back into respectability after so many cycles of hype and
       relative failure — partly due to the profitability of machine
       learning on big data. But I don’t think the predominant
       machine-learning paradigms of classification, regression,
       clustering, and dimensionality reduction contain sufficient
       richness to express the problems that a sophisticated intelligence
       must solve. This hasn’t stopped AI from being used as a marketing
       label — despite the lingering stigma, this label is reclaiming its
       marketing mojo.

   This list is not exhaustive. Other conceptualizations of AI include the
   superintelligence that might emerge — through mechanisms never made
   clear — from a sufficiently complex network like the Internet, or the
   result of whole-brain emulation (i.e., mind uploading).

   Each archetype is embedded in a deep mesh of associations, assumptions,
   and historical and fictional narratives that work together to suggest
   the technologies most likely to succeed, the potential applications and
   risks, the timeline for development, and the “personality” of the
   resulting intelligence. I’d go so far as to say that it’s impossible to
   talk and reason about AI without reference to some underlying
   characterization. Unfortunately, even sophisticated folks who should
   know better are prone to switching mid-conversation from one version of
   AI to another, resulting in arguments that descend into contradiction
   or nonsense. This is one reason that much AI discussion is so muddled —
   we quite literally don’t know what we’re talking about.

   For example, some of the confusion about deep learning stems from it
   being placed in multiple buckets: the technology has proven itself
   successful as a big-data learner, but this achievement leads many to
   assume that the same techniques can form the basis for a more complete
   interlocutor, or the basis of intelligent robotic behavior. This
   confusion is spurred by the Google mystique, including Larry Page’s
   stated drive for conversational search.

   It’s also important to note that there are possible intelligences that
   fit none of the most widely held stereotypes: that are not
   linguistically sophisticated; that do not possess a traditional robot
   embodiment; that are not primarily goal driven; and that do not sort,
   learn, and optimize via traditional big data.

   Which of these archetypes do I find most compelling? To be honest, I
   think they all fall short in one way or another. In my next post, I’ll
   put forth a new conception: AI as model-building. While you might find
   yourself disagreeing with what I have to say, I think we’ll at least
   benefit from having this debate explicitly, rather than talking past
   each other.

   Illustration on home and category pages by Pearson Scott Foresman, via
   Wikimedia Commons.
   tags: AI archtypes, artificial intelligence, intelligence matters
   Comments: 6

Get the O’Reilly Data Newsletter

   Stay informed. Receive weekly insight from industry insiders.

   IFRAME:
   //cdn.oreillystatic.com/oreilly/email/forms/email_signup_widget.html?si
   te=radar&topic=data&loc=botpost&emtype=nl

     * Richard Green
       There are lots of different kinds of human “intelligence”.
       Street smarts, math smarts, wood lore, social skill, verbal skill,
       game skill, eye-hand coordination, situation awareness, spatial
       orientation.
       Human collectives also demonstrate “intelligence”:
       building large systems (e.g. Apollo), operating large
       organizations.
       Why should we expect artificial intelligence to be any less
       diverse?
     * http://doubleclix.wordpress.com/ Krishna Sankar
       Good points. Yep, the term AI is used everywhere, many times not in
       the right context. Contemporary AI has evolved – the focus is on
       “Think Like Humans” & “Augmented Cognition” rather than the legacy
       expert systems that focused on “Work like Humans”. Transcendence
       not withstanding, Contemporary
       Artificial Intelligence & Feature Learning are being explored for
       the next
       evolution of Machine Learning, Inferences & Insights. May be
       Artificial Intelligence is not the right moniker, especially as the
       machines learn to think from the workings of our brains !
       [http://goo.gl/Ypr6oO]
       Cheers
     * Jay Kapor
       I’m impressed, I must say. Very rarely do I come across a blog
       that’s both
       informative and entertaining, and let me tell you, you’ve hit the
       nail on the
       head. Your blog is important; the issue is something that not
       enough people are
       talking intelligently about.
       UK-GG
     * polybiblios
       “For example, some of the confusion about deep learning stems from
       it being placed in multiple buckets: the technology has proven
       itself successful as a big-data learner, but this achievement leads
       many to assume that the same techniques can form the basis for a
       more complete interlocutor, or the basis of intelligent robotic
       behavior. This confusion is spurred by the Google mystique,
       including Larry Page’s stated drive for conversational search.”
       “Deep Learning” is another term with multiple meanings. If one uses
       it to just refer to complex neural nets (which is not what it means
       to specialists), then i’m not so sure it can’t “form the basis for
       a more complex interlocuter” — e.g. something like this
       http://www.overcomplete.net/papers/bica2012.pdf
       But a lot more advanced.
     * Tran Khanh
       Great article, seems like AI will be a booming technology in the
       future.
       http://www.tuicoding.com
     * Sheldon Rampton
       There are a couple more things I thought I’d add here that I
       haven’t said already. First, I strongly agree with the main premise
       of your original article, namely that definitions really matter
       when discussing whether something really is or is not “artificial
       intelligence.” If your definition is loose enough, a child’s doll
       that utters prerecorded phrases can be considered “intelligent,”
       and the children who play with those dolls may in fact sometimes
       even think that their toys have minds and personalities. At a
       somewhat higher level of complexity, computers that speak like Siri
       or that play chess or compete on Jeopardy display enough of the
       behaviors we associate with human reasoning for someone to
       reasonably claim that they have created a form of artificial
       intelligence. If all they’re trying to do is create some useful
       software that mimics intelligent behavior, that’s a perfectly
       reasonable reasoanble definition.
       Second, though, I think it is worth exploring people’s motivations
       for coining the term “artificial intelligence.” If all we really
       wanted was to make some useful tools, we wouldn’t call them
       “intelligent.” We’d just say they were useful. A lot of the
       excitement and interest in artificial intelligence comes from
       another motivation: a near-religious excitement about the
       possibility of doing something that seems godlike and creating new
       forms of sentient life ourselves.Even if we don’t express that idea
       in explicitly religious terms, there is still an emotion in the air
       that says creating machines which think the way we do would be
       really, really cool. That emotion is certainly understandable (I
       feel it myself), but it probably motivates people to want to see
       success at building AI even when all they’ve done is create an
       ingenious algorithm.
       The other thing that probably creates a tendency to see success too
       early is the human tendency to anthropomorphize. We have a natural
       tendency to create artifacts that resemble ourselves and to
       associate human qualities even with things that don’t resemble us.
       Ancient Greek mythology saw intelligent spirits that they called
       “gods” creating all of the motion in the world — thunder,
       lightning, seasons, etc. Even with clearly inanimate objects like a
       car or a TV set that isn’t working properly, we’ll get angry and
       curse at them as though we’re dealing with a person who is just
       being uncooperative. My wife has all kinds of stories that she
       tells about our cat George, in which she attributes motives and
       reasoning to him that probably have more to do with her thought
       patterns than with his. She does the same thing with Siri on her
       iPhone. I’ve seen her have actual arguments with Siri in which she
       gets angry because Siri gives the wrong response: “No, no, I told
       you already that’s not what I meant. Why won’t you listen?” Siri is
       just good enough at mimicking human behavior that it’s easy to fill
       in the blanks with our habitual tendency to project human
       attributes onto inanimate objects and think we’re dealing with
       another intelligent entity.
       I expect, therefore, that we’ll continue to see successful new
       products emerge in the marketplace that mimic human intelligence or
       that augment intelligence in various ways. They’ll be useful and
       entertaining, but we’re probably quite some ways away still from
       producing intelligence that truly possesses self-awareness or is
       capable of independent, original thought. It’s going to be fun to
       see what people come up with though.

Featured Video

   From FOO Camp 2014: Tony Haile's five-minute presentation on how to
   visit the North Pole and what you need to know before you go.

Recent Posts

     * Python 3: threat or menace?
     * Four short links: 26 September 2014
     * Four short links: 25 September 2014
     * Scaling NoSQL databases: 5 tips for increasing performance
     * In pursuit of universal IoT standards

   Tweets by @radar

Most Recently Discussed

Featured Download

                                  [cat.gif]
                         Download the free report >
                             More free reports >

Archives

     * [Archives by Month...]
     * [Archives by Topic…_]
       View
     * [Archives by Author...________]
       View

CONTACT US

   Radar managing editor
   Jenn Webb
   Sign up today to receive special discounts,
   product alerts, and news from O'Reilly.
   Enter Email_ submit
   Privacy Policy > View Sample Newsletter >
     * Twitter
     * YouTube
     * Slideshare
     * Facebook
     * Google+
     * RSS
     * View All RSS Feeds >

   © 2014, O'Reilly Media, Inc.

   (707) 827-7019(800) 889-8969

   All trademarks and registered trademarks appearing on oreilly.com are
   the property of their respective owners.

About O'Reilly

     * About O’Reilly Radar
     * Radar Contributors
     * Academic Solutions
     * Jobs
     * Contacts
     * Corporate Information
     * Press Room
     * Privacy Policy
     * Terms of Service
     * Writing for O’Reilly
     * Editorial Independence

Community

     * Authors
     * Community & Featured Users
     * Forums
     * Membership
     * Newsletters
     * O’Reilly Answers
     * RSS Feeds
     * O’Reilly Chimera (beta)

Partner Sites

     * makezine.com
     * makerfaire.com
     * craftzine.com
     * igniteshow.com
     * PayPal Developer Zone
     * O’Reilly Insights on Forbes.com

Shop O'Reilly

     * Customer Service
     * Contact Us
     * Shipping Information
     * Ordering & Payment
     * Affiliate Program
     * The O’Reilly Guarantee

   close

Get the O’Reilly Data Newsletter

   Stay informed. Receive weekly insight from industry insiders.

   IFRAME:
   //cdn.oreillystatic.com/oreilly/email/forms/email_signup_widget.html?si
   te=radar&topic=data&loc=overlay&emtype=nl
